{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GuidedBackprop_CREs-prediction\n",
    "\n",
    "This code outputs confidence values for prediction of CREs and visualize the residues relevant to the prediction, in a batch system.\n",
    "\n",
    "INPUT\n",
    "1. Sequence tiles (originally 31-bp) to visualualize relevance to prediction of TF-binding sites (or CREs).\n",
    "   NOTE: adjust the shape of sequence tiles to the originally trained one.\n",
    "2. h5 model trained with cistrome data, which was used for prediction of TF-binding sites (or CREs).\n",
    "\n",
    "OUTPUT\n",
    "1. \"prediction_test.txt\" including confidences in prediction of CREs, for each sequence tiles.\n",
    "2. Heatmaps of relevant residues in sequence tiles, in ./GBPheatmap_CREs/ directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from visualizations_forCisDecode import GradCAM, GuidedGradCAM, GBP, LRP, CLRP, SGLRP, LRPA, LRPB, LRPE\n",
    "from keras.layers import (Activation, Add, GlobalAveragePooling2D,\n",
    "                          BatchNormalization, Conv1D, Conv2D, Dense, Flatten, Reshape, Input, Dropout,\n",
    "                          MaxPooling1D,MaxPooling2D)\n",
    "\n",
    "from helper_forCisDecode2 import heatmap, heatmap_optional\n",
    "import innvestigate.utils as iutils\n",
    "import os\n",
    "from keras.models import load_model, Model\n",
    "from keras.utils import plot_model,np_utils\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "\n",
    "from functools import reduce\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import skimage as sk\n",
    "sk.__version__\n",
    "\n",
    "# limits tensorflow to a specific GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### inputs ###\n",
    "\n",
    "frag = '31bp-fragments.fa' ### 31-bp fragments for relevance propagation\n",
    "trained_model = \"example2.h5\" ### h5 model trained with cistrome data, which was used for prediction of TF-binding sites, or CREs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dna2num(dna):\n",
    "    if dna.upper() == \"A\":\n",
    "        return 0\n",
    "    elif dna.upper() == \"T\":\n",
    "        return 1\n",
    "    elif dna.upper() == \"G\":\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "    \n",
    "def num2dna(num):\n",
    "    if num == 0:\n",
    "        return \"A\"\n",
    "    elif num == 1:\n",
    "        return \"T\"\n",
    "    elif num == 2:\n",
    "        return \"G\"\n",
    "    else:\n",
    "        return \"C\"\n",
    "\n",
    "def dna2array(DNAstring):\n",
    "    numarr = []\n",
    "    length = len(DNAstring)\n",
    "    for i in range(0, length): \n",
    "        num = dna2num(DNAstring[i:i+1]) \n",
    "        if num >= 0:\n",
    "            numarr.append(num) \n",
    "    return numarr\n",
    "\n",
    "def array2dna(numarr):\n",
    "    DNAstring = []\n",
    "    length = numarr.shape[0]\n",
    "    for i in range(0, length): \n",
    "        dna = num2dna(numarr[i].argmax()) \n",
    "        DNAstring.append(dna) \n",
    "    DNAstring = ''.join(DNAstring)\n",
    "    return DNAstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    X = []\n",
    "    Y = []\n",
    "    f = open(frag, \"r\")\n",
    "    line=f.readline()\n",
    "    while line:\n",
    "        line2 = line.rstrip()\n",
    "        OneHotArr = np.array([np.eye(4)[dna2array(line2)]])\n",
    "        X.extend(OneHotArr)\n",
    "        Y.append(1)\n",
    "        line = f.readline()\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    Y = np_utils.to_categorical(Y, 2)    \n",
    "    X = np.reshape(X,(-1, 31, 4, 1))\n",
    "   \n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_shape=(82055,31,4,1)\n",
    "num_classes=2\n",
    "model = load_model(trained_model)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
    "print(model.summary())  #modelのsummaryを表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "partial_model = Model(\n",
    "    inputs=model.inputs,\n",
    "    outputs=iutils.keras.graph.pre_softmax_tensors(model.outputs),\n",
    "    name=model.name,\n",
    ")\n",
    "partial_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, Y = load_data()\n",
    "orig_imgs  = X.reshape((-1,31,4,1))\n",
    "orig_names = []\n",
    "for img in orig_imgs:\n",
    "    orig_names.append(array2dna(img))\n",
    "    \n",
    "predictions = model.predict(orig_imgs)\n",
    "pred_classes = np.argmax(predictions, axis=1)\n",
    "target_classes = np.argmax(Y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### output prediction confidence in \"prediction_test.txt\" ####\n",
    "\n",
    "write_file = \"./prediction_test.txt\"\n",
    "\n",
    "negaposi = [\"nega\",\"posi\"]\n",
    "\n",
    "with open(write_file,'w') as f:\n",
    "    f.write('prediction[nega, posi]:\\n')\n",
    "    for i in range(len(orig_names)):\n",
    "        f.write(str(i)+\"\\t\"+str(orig_names[i])+\"\\t\"+str(negaposi[target_classes[i]])+\"\\t\"+str(negaposi[pred_classes[i]])+\"\\t\"+str(predictions[i])+\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Guided backpropagation ###\n",
    "\n",
    "imagefolder = \"./GBPheatmap_CREs/\"\n",
    "\n",
    "### GBP ###\n",
    "guidedbackprop_analyzer = GBP(\n",
    "    partial_model,\n",
    "    target_id=1,### target \"positive\"\n",
    "    relu=True,\n",
    ")\n",
    "\n",
    "rate = 0.5 ### threshold value to relative relevance level 0-1\n",
    "alpha = 1 ### alpha value\n",
    "transp = \"False\" ### transparency\n",
    "\n",
    "for i in range(len(orig_names)):\n",
    "    example_id = i\n",
    "    input_img = np.copy(orig_imgs[example_id])\n",
    "    input_img_1 = np.reshape(input_img,(1,31,4,1))\n",
    "\n",
    "    # Which class you want to target.\n",
    "    Xd =array2dna(orig_imgs[example_id])\n",
    "    target_class = target_classes[example_id]\n",
    "    pred_class = pred_classes[example_id]\n",
    "    pred_score = predictions[example_id]\n",
    "    analysis_guidedbackprop = guidedbackprop_analyzer.analyze(input_img_1)\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 8), dpi=300)\n",
    "    analysis_guidedbackprop = guidedbackprop_analyzer.analyze(input_img_1)\n",
    "    heatmap_optional(analysis_guidedbackprop[0].sum(axis=(2)), r=rate, alp=alpha)\n",
    "    fig.savefig(imagefolder + str(Xd) + \".png\", transparent=transp)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
